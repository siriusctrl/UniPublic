{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 5\n",
    "## Support Vector Machines\n",
    "***\n",
    "\n",
    "In this section, we'll explore how the SVM hyperparameters (i.e. the penalty parameter, the kernel, and any kernel parameters) affect the decision surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data set\n",
    "To make visualisation and training easy, we'll consider a small binary classification data set called `cats.csv` (available from the LMS). \n",
    "It contains observations for 150 cats.\n",
    "There are two features: heart and body weight measured in kilograms.\n",
    "The target variable is the sex of the cat (we encode 'male' as`-1` and 'female' as `+1`).\n",
    "\n",
    "\\[Note: the data set originates from the following paper: R. A. Fisher (1947) _The analysis of covariance method for the relation between a part and the whole_, Biometrics **3**, 65â€“68\\]\n",
    "\n",
    "Ensure that `cats.csv` is located in the same directory as this notebook, then run the following code block to read the CSV file using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('cats.csv')\n",
    "full_df.SEX = full_df.SEX.map({'M': -1, 'F': 1})\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train/test sets so that we can evaluate our trained SVM.\n",
    "(Note that this is likely to be unreliable for such a small data set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(full_df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVMs incorporate a penalty term for the weights (proportional to $\\|\\mathbf{w}\\|_2^2$), it's usually beneficial to _standardise_ the features so that they vary on roughly the same scale.\n",
    "\n",
    "***\n",
    "**Exercise:** Complete the code block below to standardise the features, so that each feature has zero mean/unit variance.\n",
    "\n",
    "_Hint: use `StandardScaler` imported above._\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = ... # fill in\n",
    "y_train = ... # fill in\n",
    "\n",
    "X_test = ... # fill in\n",
    "y_test = ... # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training data. Notice that it's not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[y_train==1,0], X_train[y_train==1,1], label=\"Female ($y=1$)\", c='r')\n",
    "plt.scatter(X_train[y_train==-1,0], X_train[y_train==-1,1], label=\"Male ($y=-1$)\", c='b')\n",
    "plt.xlabel(\"Heart weight\")\n",
    "plt.ylabel(\"Body weight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parameter grid search\n",
    "Since the data is clearly not linearly separable, we're going to fit a kernelised SVM.\n",
    "To do this, we'll use the `sklearn.svm.SVC` class, which is a wrapper for the popular [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/) library.\n",
    "\\[Aside: LIBSVM solves the dual problem using a variant of the [sequential minimal optimisation (SMO) algorithm](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf).\\]\n",
    "The corresponding primal problem is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{\\mathbf{w}, b, \\xi} \\phantom{=} & \\frac{1}{2} \\mathbf{w}^T \\mathbf{w} + C \\sum_{i = 1}^{n} \\xi_i \\\\\n",
    "      \\mathrm{subject~to} \\phantom{=} & y_{i}(\\mathbf{w}^T \\cdot \\phi(\\mathbf{x_i}) + b) \\geq 1 - \\xi_i \\\\\n",
    "                          \\phantom{=} & \\xi_i \\geq 0 \\ \\forall i\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here $C$ is the penalty parameter, $\\mathbf{w}$ are the weights, $b$ is the bias and $\\phi$ is a mapping to a higher dimensional space---related to the kernel through $K(\\mathbf{x}_i, \\mathbf{x}_j) = \\langle \\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j) \\rangle$.\n",
    "For now, we'll use the radial basis function (RBF) kernel, which is parameterised in terms of $\\gamma$ as follows:\n",
    "\n",
    "$$\n",
    "K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp(-\\gamma \\|\\mathbf{x}_i - \\mathbf{x}_j\\|^2)\n",
    "$$\n",
    "\n",
    "Returning to our classification problem: it's unclear how to set appropriate values for $C$ and $\\gamma$ (named `C` and `gamma` in `sklearn`).\n",
    "A simple way around this is to do an exhaustive cross validation grid search.\n",
    "Below we define an evenly-spaced grid in log-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 5, 8)\n",
    "gamma_range = np.logspace(-6, 1, 16)\n",
    "\n",
    "# Visualise the grid\n",
    "xx, yy = np.meshgrid(C_range, gamma_range)\n",
    "plt.plot(xx, yy, 'ko')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$C$')\n",
    "plt.ylabel(r'$\\gamma$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the grid search, we'll use the built-in `sklearn.model_selection.GridSearchCV` class.\n",
    "It evaluates the model for each combination of parameter values using cross validation, and selects the combination with the best score.\n",
    "\n",
    "We'll use `StratifiedShuffleSplit` for cross validation (it effectively generates bootstrap samples from the training data, while preserving the class ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=30, test_size=0.1, random_state=1)\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid={'gamma': gamma_range, 'C': C_range}, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best parameters are {0.best_params_} with an accuracy of {0.best_score_:.3g}\".format(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** Why aren't we using k-fold cross validation?\n",
    "***\n",
    "\n",
    "Below we visualise the cross validation accuracy over the grid of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid.cv_results_['mean_test_score'].reshape(C_range.size, gamma_range.size)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(scores, cmap='viridis')\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.xticks(np.arange(len(gamma_range)), [\"%.2e\" % gamma for gamma in gamma_range], rotation=90)\n",
    "plt.yticks(np.arange(len(C_range)), [\"%1.e\" % C for C in C_range])\n",
    "plt.title('Cross validation accuracy')\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('$C$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** Interpret this plot. Is there a clear winning combination of parameters?\n",
    "***\n",
    "\n",
    "Now that we've found the \"best\" parameters, let's fit the SVM on the entire training set (without cross-validation).\n",
    "\n",
    "(Note: we actually fit all parameter combinations, as they're needed for a plot generated below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {(C, gamma) : SVC(C=C, gamma=gamma, kernel='rbf').fit(X_train, y_train) \n",
    "               for C in C_range\n",
    "               for gamma in gamma_range}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we evaluate the \"best\" classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = (grid.best_params_[\"C\"], grid.best_params_[\"gamma\"])\n",
    "best_svm = classifiers[best_params]\n",
    "best_train_acc = best_svm.score(X_train, y_train)\n",
    "best_test_acc = best_svm.score(X_test, y_test) \n",
    "print(\"The SVM with parameters C={0[0]:.3g}, gamma={0[1]:.3g} has training accuracy {1:.3g} and test accuracy {2:.3g}.\".format(best_params, best_train_acc, best_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** How does this compare to the training accuracy?\n",
    "***\n",
    "\n",
    "Below we visualise the decision functions for all parameter combinations (double-click output to expand to 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(C_range.size, gamma_range.size, figsize=(50,20))\n",
    "border = 0.2\n",
    "\n",
    "# Build meshgrid over the feature space\n",
    "X_min = np.amin(X_train, axis=0)\n",
    "X_max = np.amax(X_train, axis=0)\n",
    "xx, yy = np.meshgrid(np.linspace(X_min[0] - border, X_max[0] + border, 100), \n",
    "                     np.linspace(X_min[1] - border, X_max[1] + border, 100))\n",
    "\n",
    "# Plot training data + decision function for all feature combinations\n",
    "for (i, C) in enumerate(C_range):\n",
    "    for (j, gamma) in enumerate(gamma_range):\n",
    "        clf = classifiers[(C, gamma)]\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        ax[i,j].set_title(\"gamma={0.gamma:.3g}; C={0.C:.3g}\".format(clf), \n",
    "                           size='medium')\n",
    "\n",
    "        ax[i,j].pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "        ax[i,j].scatter(X_train[y_train==1,0], X_train[y_train==1,1], c='r', edgecolors='k')\n",
    "        ax[i,j].scatter(X_train[y_train==-1,0], X_train[y_train==-1,1], c='b', edgecolors='k')\n",
    "        ax[i,j].set_xticks([])\n",
    "        ax[i,j].set_yticks([])\n",
    "        ax[i,j].axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** Explain how `gamma` and `C` affect the decision surface qualitatively.\n",
    "\n",
    "**Extension activity:** Re-run this section using a different kernel (e.g. the built-in polynomial kernel or a custom kernel).\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
